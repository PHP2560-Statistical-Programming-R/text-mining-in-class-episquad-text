---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
```{r}
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 
```{r}
install.packages("gutenbergr")
library(gutenbergr)
library(dplyr)
gutenberg_metadata
data("gutenbergr", package="gutenbergr")



Buddhism<- gutenberg_download(18223)
Bible<- gutenberg_download(10)
Koran<- gutenberg_download(2800)

```

```{r}
# clean data
Bible1<-Bible %>% unnest_tokens(word, text)
Buddhism1<- Buddhism %>% unnest_tokens(word, text)
Koran1<-Koran %>% unnest_tokens(word, text)
#Analysis
#Sentiment words distribution for each book
Bible1 %>% inner_join(get_sentiments("nrc")) %>% group_by(sentiment) %>% count() %>% mutate(proporation=n/sum(n))
Buddhism1 %>% inner_join(get_sentiments("nrc")) %>% group_by(sentiment) %>% count() %>% mutate(proporation=n/sum(n))
Koran1 %>% inner_join(get_sentiments("nrc")) %>% group_by(sentiment) %>% count() %>% mutate(proporation=n/sum(n))
#Find most positive words in each book
Bible1 %>% inner_join(get_sentiments("bing")) %>% filter(sentiment=="positive") %>% group_by(word) %>% count() %>% arrange(desc(n))
Buddhism1 %>% inner_join(get_sentiments("bing")) %>% filter(sentiment=="positive") %>% group_by(word) %>% count() %>% arrange(desc(n))
Koran1 %>% inner_join(get_sentiments("bing")) %>% filter(sentiment=="positive") %>% group_by(word) %>% count() %>% arrange(desc(n))
#Find most negative words in each book
Bible1 %>% inner_join(get_sentiments("bing")) %>% filter(sentiment=="negative") %>% group_by(word) %>% count() %>% arrange(desc(n))
Buddhism1 %>% inner_join(get_sentiments("bing")) %>% filter(sentiment=="negative") %>% group_by(word) %>% count() %>% arrange(desc(n))
Koran1 %>% inner_join(get_sentiments("bing")) %>% filter(sentiment=="negative") %>% group_by(word) %>% count() %>% arrange(desc(n))
#Find positive/negative proportion for each book
Bible1 %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% count() %>% mutate(proportion=n/sum(n))
Buddhism1 %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% count() %>% mutate(proportion=n/sum(n))
Koran1 %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% count() %>% mutate(proportion=n/sum(n))
#Sentiment score per word for each book
Bible1 %>% inner_join(get_sentiments("afinn")) %>% summarize(score_per_word=sum(score)/nrow(Bible1))
Buddhism1 %>% inner_join(get_sentiments("afinn")) %>% summarize(general_sentiment=sum(score)/nrow(Buddhism1))
Koran1 %>% inner_join(get_sentiments("afinn")) %>% summarize(general_sentiment=sum(score)/nrow(Koran1))

```
